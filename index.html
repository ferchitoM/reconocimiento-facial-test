<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" href="css/styles.css">
    <script src="js/face-api.js"></script>
    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
</head>

<body>
    <div id="navbar"></div>
    <div class="center-content page-container">

        <div class="progress" id="loader">
            <div class="indeterminate"></div>
        </div>
        <div style="position: relative" class="margin">
            <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
            <canvas id="overlay">
        </div>
    </div>

    <button onclick="faceMatch()">MATCH</button>

    <div style="position: relative" class="margin">
        <img id="queryImg" src="img/img3.jpeg" style="max-width: 300px;">
        <canvas id="queryImgOverlay" class="overlay">
    </div>

</body>

<script>
    var faceMatcher = null
    var isFaceDetectionModelLoaded = false
    var minConfidence = 0.5

    async function onPlay()
    {
        const videoEl = $('#inputVideo').get(0)

        if (videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded)
            return setTimeout(() => onPlay())

        const options = faceapi.SsdMobilenetv1Options({ minConfidence })
        const ts = Date.now()
        const result = await faceapi
            .detectAllFaces(videoEl, options)
            .withFaceLandmarks()
            .withFaceExpressions()
            .withFaceDescriptors()

        if (result)
        {
            const confidence = 0.05
            const canvas = $('#overlay').get(0)
            const dims = faceapi.matchDimensions(canvas, videoEl, true)
            faceapi.draw.drawDetections(canvas, faceapi.resizeResults(result, dims))

            const resizedResults = faceapi.resizeResults(result, dims)
            faceapi.draw.drawFaceLandmarks(canvas, resizedResults)
            faceapi.draw.drawFaceExpressions(canvas, resizedResults, confidence)

            resizedResults.forEach(({ detection, descriptor }) =>
            {
                const label = faceMatcher.findBestMatch(descriptor).toString()
                const options = { label }
                const drawBox = new faceapi.draw.DrawBox(detection.box, options)
                drawBox.draw(canvas)
            })
        }

        setTimeout(() => onPlay())
    }

    async function loadImage()
    {
        const inputImgEl = $('#queryImg').get(0)
        const canvas = $('#queryImgOverlay').get(0)

        const options = faceapi.SsdMobilenetv1Options({ minConfidence })
        const results = await faceapi
            .detectAllFaces(inputImgEl, options)
            .withFaceLandmarks()
            .withFaceDescriptors()

        faceMatcher = new faceapi.FaceMatcher(results)
        faceapi.matchDimensions(canvas, inputImgEl)
        const resizedResults = faceapi.resizeResults(results, inputImgEl)

        resizedResults.forEach(({ detection, descriptor }) =>
        {
            const label = faceMatcher.findBestMatch(descriptor).toString()
            const options = { label }
            const drawBox = new faceapi.draw.DrawBox(detection.box, options)
            drawBox.draw(canvas)
        })
    }

    async function run()
    {
        // load face detection model
        const path = window.location.href
        await faceapi.loadSsdMobilenetv1Model(path + '/models')
        await faceapi.loadFaceLandmarkModel(path + '/models')
        await faceapi.loadFaceRecognitionModel(path + '/models')
        await faceapi.loadFaceExpressionModel(path + '/models')
        isFaceDetectionModelLoaded = true
        console.log("Models loaded!")

        // try to access users webcam and stream the images
        // to the video element
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
        const videoEl = $('#inputVideo').get(0)
        videoEl.srcObject = stream

        loadImage()
    }

    function updateResults() { }
    $(document).ready(function ()
    {
        run()
    })
</script>
</body>

</html>